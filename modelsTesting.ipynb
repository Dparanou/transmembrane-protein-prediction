{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, matthews_corrcoef, balanced_accuracy_score\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_proteins_dataframe.csv', index_col=0)\n",
    "\n",
    "X = df.iloc[:, 4:43]\n",
    "X = X.drop(['pdb_res_index'], axis=1)\n",
    "X = X.drop(['res_index'], axis=1)\n",
    "y = df['tm_segment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False) # 7 indicates that always get the same split of data each time this example is executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_metric = 'accuracy'\n",
    "outer_metrics = ['roc_auc', 'accuracy', 'f1']\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_inner = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "cv_outer = StratifiedKFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# define parameters\n",
    "rf_params = {\"n_estimators\": Integer(100, 2000),\n",
    "                 \"max_depth\": Integer(1, 100),\n",
    "                 \"min_samples_split\": Integer(2, 10),\n",
    "                 \"min_samples_leaf\": Integer(1, 4),\n",
    "                 \"bootstrap\": ([True, False])\n",
    "                  }\n",
    "\n",
    "outputs_rf = {}\n",
    "params_rf = []\n",
    "scores_list_rf = []\n",
    "results_rf = []\n",
    "rounds = 2\n",
    "\n",
    "for i in range(rounds):\n",
    "    # define model\n",
    "    rf_model = BayesSearchCV(estimator = rf,  scoring=inner_metric,  search_spaces = rf_params, cv = cv_inner, verbose=1,  n_jobs = 2, refit=True, n_iter=30)\n",
    "    \n",
    "    # execute the nested cross-validation\n",
    "    scores = cross_validate(rf_model, X, y, scoring=outer_metrics, cv=cv_outer, n_jobs=2, verbose=1)\n",
    "    \n",
    "    # report performance\n",
    "    output = pd.DataFrame(scores)\n",
    "    outputs_rf[i] = output\n",
    "\n",
    "    #Best\n",
    "    rf_model.fit(X, y)\n",
    "    param = rf_model.best_params_\n",
    "    print(\"\\tBest parameters:\", param)\n",
    "    params_rf.append(param)\n",
    "    \n",
    "    score = rf_model.best_score_\n",
    "    print(\"\\tBest score:\", score)\n",
    "    scores_list_rf.append(score)\n",
    "    \n",
    "    \n",
    "    result = pd.DataFrame(rf_model.cv_results_)\n",
    "    results_rf.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "\n",
    "param_grid = {\n",
    "             'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "             'gamma': Real(1e-6,  0.5, prior='log-uniform'),\n",
    "             'degree': Integer(1,8),\n",
    "             'kernel': Categorical(['linear', 'poly', 'rbf']),\n",
    "         }\n",
    "outputs_svc = {}\n",
    "params_svc = []\n",
    "scores_list_svc = []\n",
    "results_svc = []\n",
    "rounds = 2\n",
    "\n",
    "for i in range(rounds):\n",
    "    svc_model = BayesSearchCV(estimator = svc, search_spaces = param_grid, cv = cv_inner, scoring=inner_metric, verbose=1,  n_jobs = -1, refit=True, n_iter=30)\n",
    "    # execute the nested cross-validation\n",
    "    scores = cross_validate(svc_model, X, y, scoring=outer_metrics, cv=cv_outer, n_jobs=-1,verbose=1)\n",
    "    \n",
    "    # report performance\n",
    "    output = pd.DataFrame(scores)\n",
    "    outputs_svc[i] = output\n",
    "    \n",
    "    # perform the search\n",
    "    svc_model.fit(X, y)\n",
    "    # report the best result\n",
    "    \n",
    "    param = svc_model.best_params_\n",
    "    print(\"\\tBest parameters:\", param)\n",
    "    params_svc.append(param)\n",
    "    \n",
    "    score = svc_model.best_score_\n",
    "    print(\"\\tBest score:\", score)\n",
    "    scores_list_svc.append(score)\n",
    "    \n",
    "    result = pd.DataFrame(svc_model.cv_results_)\n",
    "    results_svc.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "xgb_cl = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "\n",
    "# define parameters\n",
    "param_grid = {\n",
    "    \"max_depth\": (1, 20),\n",
    "    \"n_estimators\": (10, 2000),\n",
    "    \"learning_rate\": (0.01, 0.3),\n",
    "    'subsample': (0.01, 1.0, 'uniform'),\n",
    "    'gamma': Real(1e-5, 0.5, 'log-uniform'),\n",
    "    'scale_pos_weight': (1, 5)\n",
    "}\n",
    "outputs_xgb = {}\n",
    "params_xgb = []\n",
    "scores_list_xgb = []\n",
    "results_xgb = []\n",
    "rounds = 2\n",
    "\n",
    "for i in range(rounds):\n",
    "    xgb_model = BayesSearchCV(estimator = xgb_cl, scoring=inner_metric, search_spaces = param_grid, cv = cv_inner, verbose=1,  n_jobs = -1, refit=True, n_iter=30)\n",
    "    \n",
    "    # execute the nested cross-validation\n",
    "    scores = cross_validate(xgb_model, X, y, scoring=outer_metrics, cv=cv_outer, n_jobs=-1, verbose=1, error_score='raise')\n",
    "    \n",
    "    # report performance\n",
    "    output = pd.DataFrame(scores)\n",
    "    outputs_xgb[i] = output\n",
    "    \n",
    "    #Best\n",
    "    xgb_model.fit(X, y)\n",
    "    param = xgb_model.best_params_\n",
    "    print(\"\\tBest parameters:\", param)\n",
    "    params_xgb.append(param)\n",
    "    \n",
    "    score = xgb_model.best_score_\n",
    "    print(\"\\tBest score:\", score)\n",
    "    scores_list_xgb.append(score)\n",
    "    \n",
    "    result = pd.DataFrame(xgb_model.cv_results_)\n",
    "    results_xgb.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "lgbm_cl = lgb.LGBMClassifier(objective='binary')\n",
    "\n",
    "# define parameters\n",
    "param_grid = {\n",
    "    'learning_rate': (0.01, 1),\n",
    "    'max_depth': (5, 25),\n",
    "    'num_leaves': (20, 100),\n",
    "    'num_iterations': (100, 2000),\n",
    "    'n_estimators': (50, 1000),\n",
    "    'reg_alpha': (0.01, 3),\n",
    "    'reg_lambda': (0.01, 3),\n",
    "    'bagging_fraction': (0.01, 1),\n",
    "    'bagging_freq': (0, 1),\n",
    "    'colsample_bytree': (0.01, 1),\n",
    "    'min_split_gain': (0.001, 0.1),\n",
    "    'min_child_weight': (5, 50)\n",
    "}\n",
    "outputs_lgbm = {}\n",
    "params_lgbm = []\n",
    "scores_list_lgbm = []\n",
    "results_lgbm = []\n",
    "rounds = 2\n",
    "\n",
    "for i in range(rounds):\n",
    "    lgbm_model = BayesSearchCV(estimator = lgbm_cl, scoring=inner_metric, search_spaces = param_grid, cv = cv_inner, verbose=1,  n_jobs = -1, refit=True, n_iter=30)\n",
    "    \n",
    "    # execute the nested cross-validation\n",
    "    scores = cross_validate(lgbm_model, X_test, y_test, scoring=outer_metrics, cv=cv_outer, n_jobs=-1, verbose=1, error_score='raise')\n",
    "    \n",
    "    # report performance\n",
    "    output = pd.DataFrame(scores)\n",
    "    outputs_lgbm[i] = output\n",
    "    \n",
    "    #Best\n",
    "    lgbm_model.fit(X, y)\n",
    "    param = lgbm_model.best_params_\n",
    "    print(\"\\tBest parameters:\", param)\n",
    "    params_lgbm.append(param)\n",
    "    \n",
    "    score = lgbm_model.best_score_\n",
    "    print(\"\\tBest score:\", score)\n",
    "    scores_list_lgbm.append(score)\n",
    "    \n",
    "    result = pd.DataFrame(lgbm_model.cv_results_)\n",
    "    results_lgbm.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LGBM Grid search\n",
    "model = lgb.LGBMClassifier(objective=\"binary\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [400, 700, 1000],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'max_depth': [15,20,25],\n",
    "    'num_leaves': [50, 100, 200],\n",
    "    'reg_alpha': [1.1, 1.2, 1.3],\n",
    "    'reg_lambda': [1.1, 1.2, 1.3],\n",
    "    'min_split_gain': [0.3, 0.4],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'subsample_freq': [20]\n",
    "}\n",
    "\n",
    "# define search\n",
    "rf_grid = GridSearchCV(model, param_grid, scoring='accuracy', n_jobs=-1, cv=5, verbose=2)\n",
    "\n",
    "#Best\n",
    "rf_grid.fit(X_train.drop(['pdb_id'], axis=1), y_train)\n",
    "print(\"Best parameters: \", rf_grid.best_params_)\n",
    "print(\"Best score: \", rf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.24%\n",
      "Balanced accuracy: 76.98%\n",
      "Roc: 84.04%\n",
      "F1 score: 74.97%\n"
     ]
    }
   ],
   "source": [
    "# fit model on training data\n",
    "model = XGBClassifier(objective=\"binary:logistic\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy_bl = balanced_accuracy_score(y_test, predictions)\n",
    "print(\"Balanced accuracy: %.2f%%\" % (accuracy_bl * 100.0))\n",
    "\n",
    "roc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "print(\"Roc: %.2f%%\" % (roc_score* 100.0))\n",
    "\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print(\"F1 score: %.2f%%\" % (f1* 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aaccuracy: 78.06%\n",
      "Balanced accuracy: 77.83%\n",
      "Roc: 85.62%\n",
      "F1 score: 76.05%\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma='auto', probability=True, kernel=\"linear\")\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "ypred = svm.predict(X_test)\n",
    "\n",
    "# evaluate ypred\n",
    "accuracy = accuracy_score(y_test.values, ypred)\n",
    "print(\"Aaccuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# evaluate ypred\n",
    "accuracy_bl = balanced_accuracy_score(y_test.values, ypred)\n",
    "print(\"Balanced accuracy: %.2f%%\" % (accuracy_bl * 100.0))\n",
    "\n",
    "roc_score = roc_auc_score(y_test.values, svm.predict_proba(X_test)[:, 1])\n",
    "print(\"Roc: %.2f%%\" % (roc_score* 100.0))\n",
    "\n",
    "f1 = f1_score(y_test.values, ypred)\n",
    "print(\"F1 score: %.2f%%\" % (f1* 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.59%\n",
      "Balanced accuracy: 77.29%\n",
      "Roc: 84.97%\n",
      "F1 score: 75.19%\n"
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(objective='binary')\n",
    "\n",
    "model.fit(X_train,y_train, verbose=20, eval_metric=['auc', 'logloss', 'average_precision'])\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy_bl = balanced_accuracy_score(y_test, predictions)\n",
    "print(\"Balanced accuracy: %.2f%%\" % (accuracy_bl * 100.0))\n",
    "\n",
    "roc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "print(\"Roc: %.2f%%\" % (roc_score* 100.0))\n",
    "\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print(\"F1 score: %.2f%%\" % (f1* 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.27%\n",
      "Balanced accuracy: 76.93%\n",
      "Roc: 84.13%\n",
      "F1 score: 74.66%\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy_bl = balanced_accuracy_score(y_test, predictions)\n",
    "print(\"Balanced accuracy: %.2f%%\" % (accuracy_bl * 100.0))\n",
    "\n",
    "roc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "print(\"Roc: %.2f%%\" % (roc_score* 100.0))\n",
    "\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print(\"F1 score: %.2f%%\" % (f1* 100.0))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
